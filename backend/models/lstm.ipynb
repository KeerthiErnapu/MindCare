import os
import numpy as np
import pandas as pd
import librosa
import librosa.display
import random
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from keras.src.models import Sequential
from keras.src.layers import TimeDistributed, Conv1D, BatchNormalization, Flatten, LSTM, Dense, Dropout, Reshape
from keras.src.optimizers import Adam
from keras.src.callbacks import EarlyStopping
#  Load Dataset
data_dir = r"C://Users//visha//Downloads//emotion-recognition-using-speech-master//archive (3)"  # Update this path

# Check if the directory exists
if not os.path.exists(data_dir):
    raise FileNotFoundError(f"Directory not found: {data_dir}")

# Initialize lists
file_emotion = []
file_path = []

# Read Audio Files & Extract Emotion Labels
for actor_folder in os.listdir(data_dir):
    actor_path = os.path.join(data_dir, actor_folder)
    if not os.path.isdir(actor_path):
        continue  

    for file in os.listdir(actor_path):
        file_path_full = os.path.join(actor_path, file)
        if not os.path.isfile(file_path_full):
            continue

        file_parts = file.split('.')[0].split('-')  # Remove extension & split by '-'
        if len(file_parts) > 2:
            try:
                emotion = int(file_parts[2])  # Extract emotion
                file_emotion.append(emotion)
                file_path.append(file_path_full)
            except ValueError:
                print(f"Skipping invalid file: {file}")
        else:
            print(f"Skipping improperly formatted file: {file}")

# Create DataFrame
data_path = pd.DataFrame({"Emotions": file_emotion, "Path": file_path})


emotion_mapping = {
    1: 'neutral', 2: 'calm', 3: 'happy', 4: 'sad',
    5: 'angry', 6: 'fear', 7: 'disgust', 8: 'surprise'
}
data_path['Emotions'] = data_path['Emotions'].map(emotion_mapping)

print("Sample Data:\n", data_path.head())
import os
import pandas as pd

# Define dataset directory
data_dir = r"C://Users//visha//Downloads//emotion-recognition-using-speech-master//archive (3)"  # Update this path

# Check if directory exists
if not os.path.exists(data_dir):
    raise FileNotFoundError(f"Directory not found: {data_dir}")

# Initialize lists
file_emotion = []
file_path = []

# Emotion mapping based on RAVDESS labels
emotion_mapping = {
    1: "neutral", 2: "calm", 3: "happy", 4: "sad",
    5: "angry", 6: "fear", 7: "disgust", 8: "surprise"
}

# Extract emotion labels from filenames
for actor_folder in os.listdir(data_dir):
    actor_path = os.path.join(data_dir, actor_folder)
    if not os.path.isdir(actor_path):
        continue  # Skip non-directory files

    for file in os.listdir(actor_path):
        file_path_full = os.path.join(actor_path, file)
        if not os.path.isfile(file_path_full):
            continue  # Skip non-audio files

        # Extract emotion number from filename
        file_parts = file.split('.')[0].split('-')  # Split filename by '-'
        if len(file_parts) > 2:
            try:
                emotion_num = int(file_parts[2])  # Extract third element
                emotion_label = emotion_mapping.get(emotion_num, "unknown")  # Map to label
                file_emotion.append(emotion_label)
                file_path.append(file_path_full)
            except ValueError:
                print(f"Skipping invalid file: {file}")
        else:
            print(f"Skipping improperly formatted file: {file}")

# Create DataFrame
data_path = pd.DataFrame({"Emotion": file_emotion, "Path": file_path})

# Print sample data
print("Sample Data:\n", data_path.head())

# Save to CSV
data_path.to_csv("ravdess_labeled_data.csv", index=False)
print("Labeled data saved to 'ravdess_labeled_data.csv'")
# ✅ 4️⃣ Data Augmentation Functions
def noise(data):
    noise_amp = 0.035 * np.random.uniform() * np.amax(data)
    return data + noise_amp * np.random.normal(size=data.shape[0])

def pitch(data, sampling_rate, pitch_factor=2):
    return librosa.effects.pitch_shift(y=data, sr=sampling_rate, n_steps=pitch_factor)

# ✅ 5️⃣ Feature Extraction
def extract_features(data, sample_rate):
    mfcc = librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=20)  # Extracting 20 MFCC features
    return mfcc
